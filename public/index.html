<!doctype html>
<html lang="ja">

<head>
    <meta charset="utf-8" />
    <title>QuickDictate - 音声入力→テキスト変換ツール</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link href="/css/styles.css" rel="stylesheet">
</head>

<body>
    <header>
        <h1>QuickDictate</h1>
    </header>
    <main>
        <p class="description">
            マイクで話した内容をそのままテキスト化します。「<strong>音声入力開始</strong>」ボタンを押すと、初回のみマイクへのアクセス許可を求めますので許可してください。<br>
            その後、マイクに向かって話すと、その内容がテキストに変換されて表示されます。<br>
            一定時間無言だとその部分で改行されていきます（デフォルト設定では 1 秒）。
        </p>
        <div class="mt-8 flex items-center gap-4 flex-wrap">
            <button id="start">
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                    stroke="currentColor" class="size-4" aria-hidden="true">
                    <path stroke-linecap="round" stroke-linejoin="round"
                        d="M12 18.75a6 6 0 0 0 6-6v-1.5m-6 7.5a6 6 0 0 1-6-6v-1.5m6 7.5v3.75m-3.75 0h7.5M12 15.75a3 3 0 0 1-3-3V4.5a3 3 0 1 1 6 0v8.25a3 3 0 0 1-3 3Z" />
                </svg>
                <span class="shrink-0">音声入力開始</span>
            </button>
            <div class="meter" title="音声入力レベル (概算)">
                <div class="bar" id="vu"></div>
            </div>
            <button id="stop" disabled>
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                    stroke="currentColor" class="size-4" aria-hidden="true">
                    <path stroke-linecap="round" stroke-linejoin="round"
                        d="M5.25 7.5A2.25 2.25 0 0 1 7.5 5.25h9a2.25 2.25 0 0 1 2.25 2.25v9a2.25 2.25 0 0 1-2.25 2.25h-9a2.25 2.25 0 0 1-2.25-2.25v-9Z" />
                </svg>
                <span class="shrink-0">音声入力停止</span>
            </button>
        </div>
        <div class="mt-8 flex items-center gap-4 flex-wrap">
            <button id="copy" disabled>
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                    stroke="currentColor" class="size-4" aria-hidden="true">
                    <path stroke-linecap="round" stroke-linejoin="round"
                        d="M15.666 3.888A2.25 2.25 0 0 0 13.5 2.25h-3c-1.03 0-1.9.693-2.166 1.638m7.332 0c.055.194.084.4.084.612v0a.75.75 0 0 1-.75.75H9a.75.75 0 0 1-.75-.75v0c0-.212.03-.418.084-.612m7.332 0c.646.049 1.288.11 1.927.184 1.1.128 1.907 1.077 1.907 2.185V19.5a2.25 2.25 0 0 1-2.25 2.25H6.75A2.25 2.25 0 0 1 4.5 19.5V6.257c0-1.108.806-2.057 1.907-2.185a48.208 48.208 0 0 1 1.927-.184" />
                </svg>
                <span class="shrink-0">テキストをコピー</span>
            </button>
        </div>

        <div class="mt-2">
            <div id="live" aria-live="polite" role="region" aria-label="音声入力の文字起こし結果" tabindex="0" contenteditable>
            </div>
        </div>

        <div class="mt-2 text-right">
            <button id="clear" disabled>
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                    stroke="currentColor" class="size-4" aria-hidden="true">
                    <path stroke-linecap="round" stroke-linejoin="round"
                        d="m14.74 9-.346 9m-4.788 0L9.26 9m9.968-3.21c.342.052.682.107 1.022.166m-1.022-.165L18.16 19.673a2.25 2.25 0 0 1-2.244 2.077H8.084a2.25 2.25 0 0 1-2.244-2.077L4.772 5.79m14.456 0a48.108 48.108 0 0 0-3.478-.397m-12 .562c.34-.059.68-.114 1.022-.165m0 0a48.11 48.11 0 0 1 3.478-.397m7.5 0v-.916c0-1.18-.91-2.164-2.09-2.201a51.964 51.964 0 0 0-3.32 0c-1.18.037-2.09 1.022-2.09 2.201v.916m7.5 0a48.667 48.667 0 0 0-7.5 0" />
                </svg>
                <span class="shrink-0">テキストをクリア</span>
            </button>
        </div>
    </main>

    <aside>
        <details class="space-y-4">
            <summary>
                <span class="shrink-0">デバッグログを表示</span>
                <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5"
                    stroke="currentColor" class="size-6" aria-hidden="true">
                    <path stroke-linecap="round" stroke-linejoin="round"
                        d="M8.25 15 12 18.75 15.75 15m-7.5-6L12 5.25 15.75 9" />
                </svg>
            </summary>
            <pre id="debug"></pre>
        </details>
    </aside>

    <footer>
        <span>
            by
            <a class="underline hover:no-underline" href="https://twitter.com/burnworks" target="_blank"
                aria-label="X アカウント - @burnworks">burnworks</a>
        </span>
        <svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor"
            class="size-6" aria-hidden="true">
            <path stroke-linecap="round" stroke-linejoin="round" d="m9 20.247 6-16.5" />
        </svg>
        <a class="underline hover:no-underline" href="https://github.com/burnworks/quickdictate" target="_blank"
            aria-label="QuickDictate - GitHub">GitHub</a>
    </footer>

    <script type="module">
        const $ = sel => document.querySelector(sel);
        const debugDetails = $("details");
        const dbgEl = $("#debug");
        let debugEnabled = false;

        const applyDebugVisibility = (enabled) => {
            debugEnabled = !!enabled;
            if (!debugDetails) return;
            debugDetails.hidden = !debugEnabled;
            if (debugEnabled) {
                debugDetails.open = true;
            } else {
                debugDetails.open = false;
                if (dbgEl) {
                    dbgEl.textContent = "";
                }
            }
        };

        applyDebugVisibility(false);
        const dbg = (...args) => {
            if (!debugEnabled || !dbgEl) return;
            const ts = new Date().toISOString();
            const line = args.map(a => (typeof a === "string" ? a : JSON.stringify(a))).join(" ");
            const out = `[${ts}] ${line}\n`;
            dbgEl.textContent += out;
            dbgEl.scrollTop = dbgEl.scrollHeight;
            console.log(...args);
        };

        (async () => {
            try {
                const res = await fetch("/api/debug-config");
                if (!res.ok) {
                    throw new Error("debug config fetch failed");
                }
                const data = await res.json();
                applyDebugVisibility(Boolean(data?.debug));
            } catch {
                applyDebugVisibility(false);
            }
        })();

        let pc, mediaStream, dataChannel, analyser, vuRAF;
        let accumulating = "";
        let partial = "";

        const elLive = $("#live");
        const btnStart = $("#start");
        const btnStop = $("#stop");
        const btnCopy = $("#copy");
        const btnClear = $("#clear");
        const vuBar = $("#vu");
        const defaultRealtimeModel = "gpt-4o-mini-realtime-preview";

        const fetchAsrConfig = async () => {
            const res = await fetch("/api/asr-config");
            if (!res.ok) {
                throw new Error("ASR config fetch failed");
            }
            return res.json();
        };

        const render = () => {
            const combined = [accumulating, partial].filter(Boolean).join("\n");
            const trimmed = combined.trim();
            elLive.textContent = trimmed;
            const hasText = Boolean(trimmed);
            if (btnCopy) btnCopy.disabled = !hasText;
            if (btnClear) btnClear.disabled = !hasText;
        };

        // 音声入力レベルメータ
        const startVU = (stream) => {
            try {
                const ac = new AudioContext();
                const src = ac.createMediaStreamSource(stream);
                analyser = ac.createAnalyser();
                analyser.fftSize = 512;
                src.connect(analyser);
                const data = new Uint8Array(analyser.fftSize);
                const tick = () => {
                    analyser.getByteTimeDomainData(data);
                    let min = 255, max = 0;
                    for (let i = 0; i < data.length; i++) { const v = data[i]; if (v < min) min = v; if (v > max) max = v; }
                    const amp = (max - min) / 255;
                    vuBar.style.width = Math.min(100, Math.round(amp * 160)) + "%";
                    vuRAF = requestAnimationFrame(tick);
                };
                vuRAF = requestAnimationFrame(tick);
            } catch (e) {
                dbg("VU init failed:", e?.message || String(e));
            }
        };

        // 入力音声をそのまま出力するための設定
        const sendSessionConfig = async (providedConf) => {
            try {
                const conf = providedConf ?? await fetchAsrConfig();

                const sessUpdate = {
                    type: "session.update",
                    session: {
                        turn_detection: {
                            type: "server_vad",
                            threshold: conf.vad.threshold,
                            silence_duration_ms: conf.vad.silence_duration_ms,
                        },
                        input_audio_transcription: {
                            model: conf.model,
                            language: conf.language,
                        }
                    }
                };

                dataChannel.send(JSON.stringify(sessUpdate));
                dbg("Sent session.update (ASR mode from env).", sessUpdate);
            } catch (e) {
                dbg("sendSessionConfig failed:", e?.message || String(e));
            }
        };

        const connect = async () => {
            btnStart.disabled = true;
            btnStop.disabled = true;

            try {
                dbg("Fetching ephemeral token...");
                const tokRes = await fetch("/api/realtime-token");
                const tokTxt = await tokRes.text();
                if (!tokRes.ok) {
                    throw new Error(tokTxt || "Failed to fetch realtime token");
                }
                const client_secret = JSON.parse(tokTxt).client_secret;
                if (!client_secret?.value) throw new Error("client_secret missing");

                const conf = await fetchAsrConfig();

                pc = new RTCPeerConnection();
                dataChannel = pc.createDataChannel("oai-events");
                dataChannel.onopen = () => { dbg("DataChannel open"); sendSessionConfig(conf); };
                dataChannel.onmessage = (e) => {
                    const raw = typeof e.data === "string" ? e.data : "[binary]";
                    dbg("DC message:", raw.slice(0, 200));
                    let msg; try { msg = JSON.parse(raw); } catch { return; }

                    // 認識結果イベントだけ処理
                    if (msg.type === "conversation.item.input_audio_transcription.delta") {
                        const delta = msg.delta ?? "";
                        if (delta) {
                            partial = (partial || "") + delta;
                            render();
                        }
                        return;
                    }
                    if (msg.type === "conversation.item.input_audio_transcription.completed") {
                        const finalText = (msg.transcript ?? partial ?? "").trim();
                        if (finalText) {
                            accumulating += (accumulating ? "\n" : "") + finalText;
                        }
                        partial = "";
                        render();
                        return;
                    }

                    // それ以外は無視（AIが余計な返答を返さないように） 
                };

                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaStream.getTracks().forEach(t => pc.addTrack(t, mediaStream));
                startVU(mediaStream);

                const offer = await pc.createOffer();
                await pc.setLocalDescription(offer);
                const realtimeModel = conf?.realtime_model ?? conf?.realtimeModel ?? defaultRealtimeModel;
                const realtimeUrl = `https://api.openai.com/v1/realtime?model=${encodeURIComponent(realtimeModel)}`;
                const sdpResponse = await fetch(
                    realtimeUrl,
                    {
                        method: "POST",
                        headers: {
                            Authorization: `Bearer ${client_secret.value}`,
                            "Content-Type": "application/sdp",
                        },
                        body: offer.sdp,
                    }
                );
                const text = await sdpResponse.text();
                await pc.setRemoteDescription({ type: "answer", sdp: text });

                btnStop.disabled = false;
                const hasTranscribedText = Boolean(elLive.textContent.trim());
                if (btnCopy) btnCopy.disabled = !hasTranscribedText;
                if (btnClear) btnClear.disabled = !hasTranscribedText;
            } catch (e) {
                dbg("connect failed:", e?.message || String(e));
                try { pc?.close(); } catch { }
                pc = undefined;
                dataChannel = undefined;
                if (mediaStream) {
                    mediaStream.getTracks()?.forEach(t => t.stop());
                }
                mediaStream = undefined;
                if (typeof vuRAF === "number") {
                    cancelAnimationFrame(vuRAF);
                }
                vuRAF = undefined;
                analyser = undefined;
                btnStart.disabled = false;
                btnStop.disabled = true;
                if (!elLive.textContent.trim()) {
                    if (btnCopy) btnCopy.disabled = true;
                    if (btnClear) btnClear.disabled = true;
                }
                throw e;
            }
        };

        btnStart.onclick = async () => {
            try {
                await connect();
            } catch (err) {
                alert("Connection failed. Check microphone permission and network state.");
            }
        };

        btnClear.onclick = () => {
            accumulating = "";
            partial = "";
            render();
            elLive?.focus();
        };

        btnStop.onclick = () => {
            try { pc?.close(); } catch { }
            pc = undefined;
            dataChannel = undefined;
            mediaStream?.getTracks()?.forEach(t => t.stop());
            mediaStream = undefined;
            if (typeof vuRAF === "number") {
                cancelAnimationFrame(vuRAF);
            }
            vuRAF = undefined;
            analyser = undefined;
            btnStart.disabled = false;
            btnStop.disabled = true;
            if (!elLive.textContent.trim()) {
                if (btnCopy) btnCopy.disabled = true;
                if (btnClear) btnClear.disabled = true;
            }
        };

        btnCopy.onclick = async () => {
            const text = elLive.textContent.trim();
            if (!text) return;
            await navigator.clipboard.writeText(text);
            const label = btnCopy?.querySelector("span");
            if (label) {
                label.textContent = "コピーしました";
                setTimeout(() => { label.textContent = "テキストをコピー"; }, 1200);
            }
        };
    </script>
</body>

</html>